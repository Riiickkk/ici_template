# main.py
import gradio as gr
import traceback
from data_loader import load_and_vectorize_documents
from llm_service import LLMService
from audio_service import AudioService
from config import WELCOME_TEXT, WELCOME_AUDIO_FILE

# åˆå§‹åŒ–æœå‹™
try:
    vector_store, retriever = load_and_vectorize_documents()
    llm_service = LLMService(retriever)
    audio_service = AudioService()
except Exception as e:
    print(f"åˆå§‹åŒ–æœå‹™éŒ¯èª¤ï¼š{e}")
    exit()

# å…¨åŸŸå°è©±æ­·å²è¨˜éŒ„
conversation_history = []


def intro():
    """Gradio ä»‹é¢çš„åˆå§‹ä»‹ç´¹ã€‚"""
    # å¯ä»¥åœ¨é€™è£¡æ·»åŠ é‡ç½®å°è©±æ­·å²çš„é‚è¼¯ï¼Œç¢ºä¿æ¯æ¬¡é é¢è¼‰å…¥æ™‚éƒ½æ˜¯æ–°çš„å°è©±
    global conversation_history
    conversation_history = []  # ç¢ºä¿é‡æ–°è¼‰å…¥æ™‚ä¹Ÿæ¸…ç©ºæ­·å²
    return f"ğŸ§‹ åº—å“¡ï¼š{WELCOME_TEXT}", WELCOME_AUDIO_FILE


def chat_with_voice(audio_path):
    """
    è™•ç†éŸ³é »è¼¸å…¥ã€ç”Ÿæˆ LLM å›è¦†ä¸¦å›å‚³éŸ³é »è¼¸å‡ºçš„ä¸»è¦å‡½æ•¸ã€‚
    """
    global conversation_history
    try:
        # ... (é€™è£¡çš„ chat_with_voice å‡½æ•¸å…§å®¹ä¿æŒä¸è®Šï¼Œå¦‚åŒæˆ‘ä¸Šæ¬¡æä¾›çš„ç‰ˆæœ¬) ...
        # æ­¥é©Ÿ 1ï¼šèªéŸ³è½‰æ–‡å­— (ç¾åœ¨ Whisper æœƒå›å‚³æ–‡æœ¬å’Œåµæ¸¬åˆ°çš„èªè¨€)
        raw_text, detected_lang_by_whisper = audio_service.transcribe_audio(audio_path)
        print(f"DEBUG (main.py): Whisper transcribed raw text: '{raw_text}'")
        print(f"DEBUG (main.py): Whisper detected language: '{detected_lang_by_whisper}'")

        # æ­¥é©Ÿ 2ï¼šä½¿ç”¨ LLM æ ¡æ­£èªéŸ³è½‰æ–‡å­—
        corrected_text = llm_service.correct_speech_to_text(raw_text, "")
        print(f"DEBUG (main.py): LLM corrected text (original language): '{corrected_text}'")

        # æ­¥é©Ÿ 3ï¼šå°‡æ ¡æ­£å¾Œçš„æ–‡æœ¬ç¿»è­¯æˆä¸­æ–‡ (ç”¨æ–¼ RAG æŸ¥è©¢)
        if detected_lang_by_whisper.lower() not in ["zh-tw"]:
            query_for_rag = llm_service.translate_to_chinese(corrected_text, detected_lang_by_whisper)
            print(f"DEBUG (main.py): Translated query for RAG: '{query_for_rag}'")
        else:
            query_for_rag = corrected_text
            print(f"DEBUG (main.py): Query for RAG (already zh-tw): '{query_for_rag}'")

        # æ­¥é©Ÿ 4ï¼šç²å– RAG ä¸Šä¸‹æ–‡
        rag_context = llm_service.get_rag_context(query_for_rag)

        # æ­¥é©Ÿ 5ï¼šç²å– LLM å›è¦†
        answer = llm_service.get_llm_response(
            corrected_text,
            conversation_history,
            rag_context,
            output_lang=detected_lang_by_whisper  # ä½¿ç”¨ Whisper åµæ¸¬åˆ°çš„èªè¨€
        )
        print(f"DEBUG (main.py): LLM generated answer: '{answer}'")

        # æ­¥é©Ÿ 6ï¼šæ–‡å­—è½‰èªéŸ³
        audio_output_path = audio_service.text_to_speech(answer, user_input_lang=detected_lang_by_whisper)
        print(f"DEBUG (main.py): TTS output audio path: '{audio_output_path}'")

        # æ­¥é©Ÿ 7ï¼šæ›´æ–°æ­·å²è¨˜éŒ„ä¸¦é¡¯ç¤º
        conversation_history.append((query_for_rag, answer))
        chat_log_text = ""  # æ”¹ç”¨ chat_log_text é¿å…èˆ‡ outputs è®Šæ•¸åè¡çª
        for q, a_log in conversation_history:
            chat_log_text += f"ğŸ‘¤ å®¢äººï¼š{q}\nğŸ§‹ åº—å“¡ï¼š{a_log}\n\n"

        return chat_log_text.strip(), audio_output_path  # é€™è£¡è¿”å› chat_log_text

    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{traceback.format_exc()}")
        return f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{traceback.format_exc()}", None


# ========== æ–°å¢çš„é‡ç½®å‡½æ•¸ ==========
def reset_chat():
    """é‡ç½®èŠå¤©æ­·å²è¨˜éŒ„å’Œ Gradio ä»‹é¢ã€‚"""
    global conversation_history
    conversation_history = []  # æ¸…ç©ºå°è©±æ­·å²
    print("DEBUG (main.py): Chat history reset.")
    # è¿”å›ç©ºå­—ä¸²å’Œ None ä»¥æ¸…ç©º Gradio ä»‹é¢ä¸Šçš„æ–‡æœ¬æ¡†å’ŒéŸ³é »æ’­æ”¾å™¨
    return "", None, f"ğŸ§‹ åº—å“¡ï¼š{WELCOME_TEXT}", audio_service._initialize_welcome_audio()  # è¿”å›æ­¡è¿è©å’ŒéŸ³é »


# Gradio ä»‹é¢
with gr.Blocks() as demo:
    gr.Markdown("ğŸ§‹ **èªéŸ³é»é¤ç³»çµ± - å¤šèªç‰ˆæœ¬**")

    # å®šç¾©è¼¸å‡ºå£ä»¶ (Output Components)ï¼Œä»¥ä¾¿é‡ç½®å‡½æ•¸å¯ä»¥å¼•ç”¨å®ƒå€‘
    chat_log_display = gr.Textbox(label="å°è©±ç´€éŒ„", lines=15)
    audio_output_display = gr.Audio(label="èªéŸ³å›è¦†", autoplay=True)

    # è¨­ç½®åˆå§‹æ­¡è¿è¨Šæ¯ï¼Œä¸¦å°‡å…¶è¼¸å‡ºåˆ° chat_log_display å’Œ audio_output_display
    demo.load(fn=intro, inputs=[], outputs=[chat_log_display, audio_output_display])

    with gr.Row():
        audio_input = gr.Audio(sources=["microphone", "upload"], type="filepath", label="è«‹é–‹å•Ÿéº¥å…‹é¢¨")
        # å°‡ chat_with_voice çš„è¼¸å‡ºæŒ‡å‘æ–°çš„ chat_log_display å’Œ audio_output_display
        audio_input.change(fn=chat_with_voice, inputs=audio_input, outputs=[chat_log_display, audio_output_display])

    # æ–°å¢ä¸€å€‹é‡ç½®æŒ‰éˆ•
    reset_btn = gr.Button("é‡ç½®èŠå¤©")
    # ç•¶æŒ‰éˆ•è¢«é»æ“Šæ™‚ï¼Œå‘¼å« reset_chat å‡½æ•¸ï¼Œä¸¦æ›´æ–° chat_log_display å’Œ audio_output_display
    reset_btn.click(
        fn=reset_chat,
        inputs=[],
        outputs=[chat_log_display, audio_output_display, chat_log_display, audio_output_display]
        # é‡è¤‡ chat_log_display å’Œ audio_output_display ç¢ºä¿åˆ·æ–°
    )

if __name__ == "__main__":
    demo.launch(debug=True, share=True)