import gradio as gr
import traceback
from data_loader import load_and_vectorize_documents
from llm_service import LLMService
from audio_service import AudioService
from config import WELCOME_TEXT, WELCOME_AUDIO_FILE

# åˆå§‹åŒ–æœå‹™
try:
    vector_store, retriever = load_and_vectorize_documents()
    llm_service = LLMService(retriever)
    audio_service = AudioService()
except Exception as e:
    print(f"åˆå§‹åŒ–æœå‹™éŒ¯èª¤ï¼š{e}")
    # å¦‚æœåŸºæœ¬æœå‹™è¼‰å…¥å¤±æ•—ï¼Œå‰‡é€€å‡ºæˆ–å„ªé›…è™•ç†
    exit()

# å…¨åŸŸå°è©±æ­·å²è¨˜éŒ„
conversation_history = []

def intro():
    """Gradio ä»‹é¢çš„åˆå§‹ä»‹ç´¹ã€‚"""
    return f"ğŸ§‹ åº—å“¡ï¼š{WELCOME_TEXT}", WELCOME_AUDIO_FILE

def chat_with_voice(audio_path):
    """
    è™•ç†éŸ³é »è¼¸å…¥ã€ç”Ÿæˆ LLM å›è¦†ä¸¦å›å‚³éŸ³é »è¼¸å‡ºçš„ä¸»è¦å‡½æ•¸ã€‚
    """
    global conversation_history
    try:
        # æ­¥é©Ÿ 1ï¼šèªéŸ³è½‰æ–‡å­— (ç¾åœ¨ Whisper æœƒå›å‚³æ–‡æœ¬å’Œåµæ¸¬åˆ°çš„èªè¨€)
        raw_text, detected_lang_by_whisper = audio_service.transcribe_audio(audio_path)
        print(f"DEBUG (main.py): Whisper transcribed raw text: '{raw_text}'")
        print(f"DEBUG (main.py): Whisper detected language: '{detected_lang_by_whisper}'")

        # æ­¥é©Ÿ 2ï¼šä½¿ç”¨ LLM æ ¡æ­£èªéŸ³è½‰æ–‡å­—
        # é€™è£¡çš„ corrected_text ä»ç„¶æ˜¯åŸå§‹èªè¨€ï¼Œåªæ˜¯ä¿®æ­£äº†è¾¨è­˜éŒ¯èª¤
        corrected_text = llm_service.correct_speech_to_text(raw_text, "") # RAG context æš«æ™‚å‚³ç©ºå­—ä¸²ï¼Œå› ç‚ºé‚„æ²’ç¿»è­¯
        print(f"DEBUG (main.py): LLM corrected text (original language): '{corrected_text}'")

        # æ­¥é©Ÿ 3ï¼šå°‡æ ¡æ­£å¾Œçš„æ–‡æœ¬ç¿»è­¯æˆä¸­æ–‡ (ç”¨æ–¼ RAG æŸ¥è©¢)
        # åªæœ‰ç•¶åµæ¸¬åˆ°çš„èªè¨€ä¸æ˜¯ä¸­æ–‡æ™‚æ‰é€²è¡Œç¿»è­¯
        if detected_lang_by_whisper.lower() not in ["zh", "zh-tw", "zh-cn"]:
            query_for_rag = llm_service.translate_to_chinese(corrected_text, detected_lang_by_whisper)
            print(f"DEBUG (main.py): Translated query for RAG: '{query_for_rag}'")
        else:
            query_for_rag = corrected_text # å¦‚æœæ˜¯ä¸­æ–‡ï¼Œå‰‡ç›´æ¥ä½¿ç”¨æ ¡æ­£å¾Œçš„ä¸­æ–‡æ–‡æœ¬
            print(f"DEBUG (main.py): Query for RAG (already Chinese): '{query_for_rag}'")


        # æ­¥é©Ÿ 4ï¼šç²å– RAG ä¸Šä¸‹æ–‡ï¼ˆç¾åœ¨ä½¿ç”¨ç¿»è­¯å¾Œçš„ä¸­æ–‡æŸ¥è©¢ï¼‰
        rag_context = llm_service.get_rag_context(query_for_rag)
        print(f"DEBUG (main.py): RAG context retrieved: '{rag_context}'")

        # æ­¥é©Ÿ 5ï¼šç²å– LLM å›è¦† (LLM æœƒæ ¹æ“šåŸå§‹èªè¨€å’Œ RAG context å›è¦†)
        # é€™è£¡ä»ç„¶ä½¿ç”¨ corrected_text (åŸå§‹èªè¨€) å‚³çµ¦ LLMï¼Œå› ç‚º LLM çŸ¥é“è¦ç”¨é¡§å®¢çš„èªè¨€å›è¦†
        answer = llm_service.get_llm_response(corrected_text, conversation_history, rag_context)
        print(f"DEBUG (main.py): LLM generated answer: '{answer}'")


        # æ­¥é©Ÿ 6ï¼šæ–‡å­—è½‰èªéŸ³ï¼ˆä½¿ç”¨ Whisper åµæ¸¬åˆ°çš„èªè¨€ä¾†å›è¦†ï¼‰
        audio_output_path = audio_service.text_to_speech(answer, user_input_lang=detected_lang_by_whisper)

        # æ­¥é©Ÿ 7ï¼šæ›´æ–°æ­·å²è¨˜éŒ„ä¸¦é¡¯ç¤º
        conversation_history.append((corrected_text, answer)) # æ­·å²è¨˜éŒ„ä»è¨˜éŒ„åŸå§‹èªè¨€çš„å•ç­”

        chat_log = ""
        for q, a in conversation_history:
            chat_log += f"ğŸ‘¤ å®¢äººï¼š{q}\nğŸ§‹ åº—å“¡ï¼š{a}\n\n"

        return chat_log.strip(), audio_output_path

    except Exception as e:
        return f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{traceback.format_exc()}", None

# Gradio ä»‹é¢
with gr.Blocks() as demo:
    gr.Markdown("ğŸ§‹ **èªéŸ³é»é¤ç³»çµ± - å¤šèªç‰ˆæœ¬**")

    audio_input = gr.Audio(sources=["microphone", "upload"], type="filepath", label="è«‹é–‹å•Ÿéº¥å…‹é¢¨")
    chat_log = gr.Textbox(label="å°è©±ç´€éŒ„", lines=15)
    audio_output = gr.Audio(label="èªéŸ³å›è¦†", autoplay=True)

    audio_input.change(fn=chat_with_voice, inputs=audio_input, outputs=[chat_log, audio_output])
    demo.load(fn=intro, inputs=[], outputs=[chat_log, audio_output])

if __name__ == "__main__":
    demo.launch(debug=True, share=True)
