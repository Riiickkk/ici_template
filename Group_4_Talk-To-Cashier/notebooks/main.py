import gradio as gr
import traceback
from data_loader import load_and_vectorize_documents
from llm_service import LLMService
from audio_service import AudioService
from config import WELCOME_TEXT, WELCOME_AUDIO_FILE

# åˆå§‹åŒ–æœå‹™
try:
    vector_store, retriever = load_and_vectorize_documents()
    llm_service = LLMService(retriever)
    audio_service = AudioService()
except Exception as e:
    print(f"åˆå§‹åŒ–æœå‹™éŒ¯èª¤ï¼š{e}")
    # å¦‚æœåŸºæœ¬æœå‹™è¼‰å…¥å¤±æ•—ï¼Œå‰‡é€€å‡ºæˆ–å„ªé›…è™•ç†
    exit()

# å…¨åŸŸå°è©±æ­·å²è¨˜éŒ„
conversation_history = []

def intro():
    """Gradio ä»‹é¢çš„åˆå§‹ä»‹ç´¹ã€‚"""
    return f"ğŸ§‹ åº—å“¡ï¼š{WELCOME_TEXT}", WELCOME_AUDIO_FILE

def chat_with_voice(audio_path):
    """
    è™•ç†éŸ³é »è¼¸å…¥ã€ç”Ÿæˆ LLM å›è¦†ä¸¦å›å‚³éŸ³é »è¼¸å‡ºçš„ä¸»è¦å‡½æ•¸ã€‚
    """
    global conversation_history
    try:
        # æ­¥é©Ÿ 1ï¼šèªéŸ³è½‰æ–‡å­—
        raw_text = audio_service.transcribe_audio(audio_path)

        # æ­¥é©Ÿ 2ï¼šç²å– RAG ä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨åŸå§‹æ–‡å­—é€²è¡Œåˆå§‹æª¢ç´¢ï¼‰
        rag_context = llm_service.get_rag_context(raw_text)

        # æ­¥é©Ÿ 3ï¼šä½¿ç”¨ LLM æ ¡æ­£èªéŸ³è½‰æ–‡å­—
        corrected_text = llm_service.correct_speech_to_text(raw_text, rag_context)

        # æ­¥é©Ÿ 4ï¼šç²å– LLM å›è¦†
        answer = llm_service.get_llm_response(corrected_text, conversation_history, rag_context)

        # æ­¥é©Ÿ 5ï¼šæ–‡å­—è½‰èªéŸ³ï¼ˆå¾æ ¡æ­£å¾Œçš„æ–‡å­—æª¢æ¸¬èªè¨€ï¼‰
        audio_output_path = audio_service.text_to_speech(answer, user_input_lang=None) # å°‡å¾ `answer` ä¸­æª¢æ¸¬

        # æ­¥é©Ÿ 6ï¼šæ›´æ–°æ­·å²è¨˜éŒ„ä¸¦é¡¯ç¤º
        conversation_history.append((corrected_text, answer))

        chat_log = ""
        for q, a in conversation_history:
            chat_log += f"ğŸ‘¤ å®¢äººï¼š{q}\nğŸ§‹ åº—å“¡ï¼š{a}\n\n"

        return chat_log.strip(), audio_output_path

    except Exception as e:
        return f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{traceback.format_exc()}", None

# Gradio ä»‹é¢
with gr.Blocks() as demo:
    gr.Markdown("ğŸ§‹ **èªéŸ³é»é¤ç³»çµ± - å¤šèªç‰ˆæœ¬**")

    audio_input = gr.Audio(sources="upload", type="filepath", label="è«‹ä¸Šå‚³èªéŸ³")
    chat_log = gr.Textbox(label="å°è©±ç´€éŒ„", lines=15)
    audio_output = gr.Audio(label="èªéŸ³å›è¦†", autoplay=True)

    audio_input.change(fn=chat_with_voice, inputs=audio_input, outputs=[chat_log, audio_output])
    demo.load(fn=intro, inputs=[], outputs=[chat_log, audio_output])

if __name__ == "__main__":
    demo.launch()